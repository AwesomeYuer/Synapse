{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# User-Defined Functions with Complex Types in .NET for Apache Spark\n",
        "\n",
        "A user-defined function, or UDF, is a routine that can take in parameters, perform some sort of calculation, and then return a result. UDFs are a powerful mechanism to encapsulate your business logic and use the power of Spark to execute them at scale. This notebook explains how to construct UDFs in C# and includes example functions, such as how to use UDFs with complex Row objects.\n",
        "\n",
        "[Addition Reading](https://docs.microsoft.com/en-us/dotnet/spark/how-to-guides/deploy-worker-udf-binaries)\n",
        "\n",
        "Now let's get started with some examples!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a simple DataFrame\n",
        "\n",
        "Create a DataFrame which will be used in the following examples."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame df = spark.Range(0, 5).WithColumn(\"structId\", Struct(\"id\"));"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.3318327Z",
              "execution_start_time": "2021-02-23T07:01:41.5340495Z",
              "execution_finish_time": "2021-02-23T07:01:43.5686941Z"
            },
            "text/plain": "StatementMeta(samll, 16, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDF that takes in Row objects\n",
        "\n",
        "Now, let us define a UDF that takes in Row objects and adds 100 to the original data's first column.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Func<Column, Column> udf1 = Udf<Row, int>(\n",
        "    row => row.GetAs<int>(0) + 100);"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.352183Z",
              "execution_start_time": "2021-02-23T07:01:43.642277Z",
              "execution_finish_time": "2021-02-23T07:01:45.6780499Z"
            },
            "text/plain": "StatementMeta(samll, 16, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now show how to use a UDF with DataFrames"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.Select(udf1(df[\"structId\"]).As(\"newId\")).Show();"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.3614825Z",
              "execution_start_time": "2021-02-23T07:01:45.7581193Z",
              "execution_finish_time": "2021-02-23T07:01:53.9343962Z"
            },
            "text/plain": "StatementMeta(samll, 16, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "+-----+\n|newId|\n+-----+\n|  100|\n|  101|\n|  102|\n|  103|\n|  104|\n+-----+\n\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDF that returns Row objects\n",
        "\n",
        "Often times, you might want to accept a Row as input, and construct a **new** Row based on some complex business logic. You can do this as follows:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "using Microsoft.Spark.Sql.Types;\n",
        "\n",
        "// First define the schema for Row objects\n",
        "var schema = new StructType(new[]\n",
        "{\n",
        "    new StructField(\"col1\", new IntegerType()),\n",
        "    new StructField(\"col2\", new StringType())\n",
        "});\n",
        "\n",
        "// Then define UDF that returns Row objects          \n",
        "Func<Column, Column> udf2 = Udf<int>(\n",
        "    id => new GenericRow(new object[] { id, \"abc\" }), schema);"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.3731161Z",
              "execution_start_time": "2021-02-23T07:01:54.0112746Z",
              "execution_finish_time": "2021-02-23T07:01:56.0528368Z"
            },
            "text/plain": "StatementMeta(samll, 16, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// Use UDF with DataFrames\n",
        "df.Select(udf2(df[\"id\"]).As(\"newStructId\")).Show();"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.3858362Z",
              "execution_start_time": "2021-02-23T07:01:56.124367Z",
              "execution_finish_time": "2021-02-23T07:01:58.1595142Z"
            },
            "text/plain": "StatementMeta(samll, 16, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "+-----------+\n|newStructId|\n+-----------+\n|   [0, abc]|\n|   [1, abc]|\n|   [2, abc]|\n|   [3, abc]|\n|   [4, abc]|\n+-----------+\n\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chained UDF with Row objects\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// Chained UDF using udf1 and udf2 defined above.\n",
        "df.Select(udf1(udf2(df[\"id\"])).As(\"chainedId\")).Show();"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "samll",
              "session_id": 16,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T07:00:46.3979961Z",
              "execution_start_time": "2021-02-23T07:01:58.2439975Z",
              "execution_finish_time": "2021-02-23T07:02:00.2868449Z"
            },
            "text/plain": "StatementMeta(samll, 16, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "+---------+\n|chainedId|\n+---------+\n|      100|\n|      101|\n|      102|\n|      103|\n|      104|\n+---------+\n\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "csharp"
    },
    "kernelspec": {
      "name": "synapse_sparkdotnet",
      "language": "C#",
      "display_name": "Synapse SparkDotNet"
    },
    "microsoft": {
      "language": "csharp"
    },
    "kernel_info": {
      "name": "synapse_sparkdotnet"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}